
Next-generation scientific instruments will collect data at unprecedented rates: multi-GB/s and 100+ TB/day.  Such runs will benefit from automation via machine learning methods to enable online steering, but learning from online streams needs advanced data management and policy techniques.  The Braid project orchestrates data flows using modular and repurposable actions and integrates them with HPC resources, while enforcing data policies, i.e., data capture quality and performance.  Interpreting such automatic decisions to understand progress, performance, policy adherence, and validate scientific results will be challenging and will require novel techniques. New provenance concepts and systems are needed to capture not just in the data obtained, but also the models produced, which may be more important in the era of AI for science.

This paper presents Braid-DB, a provenance system that embraces AI for science automation in how and when to analyze and retain data, and when to alter experimental configurations.  Traditional provenance systems automate the record-keeping so that humans and/or machines can recover how a particular result was obtained and, when failures occur, diagnose causes, and enable rapid restart.  The Braid project (and related efforts) necessitate additional recording about what went into model training, including external data, simulations, and the structures of other learning and analysis activity.

The approach presented here will mix and match concepts from the provenance literature with popular version control concepts to provide a robust and usable solution.  It develops recursive and versioned provenance structures; capturing how models may be constructed via other models (e.g. estimators and  surrogates), and the fact that models are constantly updated, allowing the user to track past decisions as models make decisions and are retrained.

The presentation will survey about 5 partner apps for use cases and requirements.  We will also sketch the relevant Python-oriented data models, the internal persistent formats, and the APIs that may be used to access the system via the wide area or from HPC jobs.
